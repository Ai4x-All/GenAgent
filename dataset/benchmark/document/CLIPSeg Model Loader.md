- `CLIPSeg Model Loader`: This node is designed to load a CLIPSeg model, which is a specialized model for image segmentation using CLIP (Contrastive Languageâ€“Image Pretraining). It facilitates the integration of CLIPSeg's capabilities into workflows, enabling advanced image segmentation tasks that leverage both textual and visual information.
    - Inputs:
        - `model` (Required): Specifies the model to be loaded. The default model is 'CIDAS/clipseg-rd64-refined'. This parameter allows for the selection of different CLIPSeg models based on the task requirements. Type should be `STRING`.
    - Outputs:
        - `clipseg_model`: Outputs a tuple containing the CLIPSeg model and its processor, ready for image segmentation tasks. Type should be `CLIPSEG_MODEL`.
