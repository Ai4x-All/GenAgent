- `MotionDiffSimpleSampler`: The MotionDiffSimpleSampler node is designed to facilitate the sampling process within a motion diffusion framework, specifically targeting the generation or transformation of motion data. It abstracts the complexities involved in selecting and applying different sampling strategies, such as uniform or loss-aware sampling, to produce or modify motion sequences based on given conditions and inputs.
    - Parameters:
        - `sampler_name`: Specifies the name of the sampling strategy to be used, affecting the choice of algorithm for generating or transforming motion data. Type should be `COMBO[STRING]`.
        - `seed`: A seed value to ensure reproducibility of the generated or transformed motion data. Type should be `INT`.
    - Inputs:
        - `md_model`: A wrapper around the motion diffusion model, providing the necessary interface for the sampling process. Type should be `MD_MODEL`.
        - `md_clip`: Represents the clip information required for motion generation or transformation, encapsulating the model and its associated data. Type should be `MD_CLIP`.
        - `md_cond`: The conditions under which the motion data is to be generated or transformed, guiding the sampling process. This includes text and motion data processed by the MotionCLIPTextEncode node. Type should be `MD_CONDITIONING`.
        - `motion_data`: The input motion data that will be transformed or generated anew, depending on the sampling strategy. Includes motion, motion mask, and motion length. Type should be `MOTION_DATA`.
    - Outputs:
        - `motion_data`: The output motion data after sampling, including the generated or transformed motion sequence, motion mask, and motion length. Type should be `MOTION_DATA`.
