This workflow uses multiple nodes based on Stable Video Diffusion to generate a video from an image. Given an image, the workflow will convert it into video conditioning and corresponding latent code, which will be fed into the sampler and decoder to generate the video. In this example, we generate a video of a girl playing the guitar based on the given image. Image size of 1024x768, 24 frames and 6 frames per second are recommended for the best results.