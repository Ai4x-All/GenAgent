- `IPAdapterTiledBatch`: The IPAdapterTiledBatch node is designed to apply image processing adaptations in a batched, tiled manner to images, leveraging an underlying IPAdapter model. It enhances image processing by unfolding batches for more efficient computation, particularly suitable for handling large images or multiple image segments simultaneously.
    - Parameters:
        - `weight`: A floating-point value that influences the adaptation process, potentially altering the intensity or effect of the applied adaptations. Type should be `FLOAT`.
        - `weight_type`: Determines the type of weighting applied during the adaptation process, affecting how the modifications are calculated and applied. Type should be `COMBO[STRING]`.
        - `start_at`: A floating-point value indicating the starting point of the adaptation effect, allowing for gradual application over the image. Type should be `FLOAT`.
        - `end_at`: A floating-point value indicating the end point of the adaptation effect, enabling precise control over where the adaptations cease. Type should be `FLOAT`.
        - `sharpening`: A floating-point value that adjusts the sharpness of the image, enhancing detail and clarity. Type should be `FLOAT`.
        - `embeds_scaling`: Specifies the approach to scaling embeddings during the adaptation process, impacting the adaptation's effect on the image. Type should be `COMBO[STRING]`.
    - Inputs:
        - `model`: Specifies the model to which the IPAdapter modifications will be applied, serving as the foundation for the image processing tasks. Type should be `MODEL`.
        - `ipadapter`: Defines the IPAdapter to be used for processing the images, indicating the specific adaptation logic to apply. Type should be `IPADAPTER`.
        - `image`: The image to be processed, which can be segmented into tiles for batch processing. Type should be `IMAGE`.
        - `image_negative`: An optional negative image input that can be used to specify areas of the image to be de-emphasized or altered in contrast to the primary image. Type should be `IMAGE`.
        - `attn_mask`: An optional attention mask that can be applied to focus or defocus certain areas of the image during the adaptation process. Type should be `MASK`.
        - `clip_vision`: An optional CLIP vision model input that can be used to guide the adaptation process based on visual concepts. Type should be `CLIP_VISION`.
    - Outputs:
        - `MODEL`: The modified model after applying the IPAdapter adaptations. Type should be `MODEL`.
        - `tiles`: The processed image tiles resulting from the batched, tiled adaptation process. Type should be `IMAGE`.
        - `masks`: The masks applied to each tile during the adaptation process, indicating areas of focus or alteration. Type should be `MASK`.
