- `LLMLLaVANextImageEvaluator`: This node is designed to evaluate images using the LLaVA Next V1 model, generating descriptions or captions based on the provided prompts and images. It abstracts the complexity of image processing and model evaluation, offering a streamlined interface for generating textual representations of images.
    - Parameters:
        - `max_tokens`: Specifies the maximum number of tokens to be generated for each image description. This parameter controls the verbosity and detail level of the output captions. Type should be `INT`.
        - `prompt_format`: The format used to construct the prompt for the model, incorporating the image and user instructions into a structured template. Type should be `STRING`.
        - `prompt`: The specific prompt or instruction given to the model for generating the image description, influencing the context and focus of the generated text. Type should be `STRING`.
    - Inputs:
        - `lnv1_model`: The LLaVA Next V1 model used for evaluating the images. It is crucial for the execution as it directly influences the quality and relevance of the generated captions. Type should be `LLAVA_NEXT_V1_MODEL`.
        - `images`: A batch of images represented as tensors. These images are the subject of evaluation and caption generation, serving as the primary input for the model. Type should be `IMAGE`.
    - Outputs:
        - `strings`: The raw strings generated as image descriptions. Type should be `STRING`.
        - `list`: A list of raw strings, each representing a generated description for the input images. Type should be `LIST`.
        - `documents`: A collection of Document objects, each encapsulating a generated image description along with additional metadata such as user prompts and image thumbnails. Type should be `DOCUMENT`.
