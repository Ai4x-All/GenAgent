- `LLMGroqModel`: The LLMGroqModel node is designed to interface with the Groq platform for loading and managing language models. It encapsulates the functionality for initializing language models and their corresponding embedding models, providing a streamlined process for integrating Groq's AI capabilities into various applications.
    - Parameters:
        - `model`: Specifies the name of the language model to be loaded. This parameter is crucial for determining which specific model from the Groq platform will be utilized during the operation. Type should be `COMBO[STRING]`.
        - `groq_api_key`: The API key required for authenticating with the Groq platform. This key enables secure access to Groq's services and is essential for the operation of the node. Type should be `STRING`.
        - `embedding_model`: Defines the name of the embedding model to be used in conjunction with the language model. This parameter is important for tasks that require semantic understanding of text, such as similarity searches or text classification. Type should be `COMBO[STRING]`.
        - `openai_api_key`: An optional API key for OpenAI services, used when the embedding model is based on OpenAI's technology. Type should be `STRING`.
    - Inputs:
    - Outputs:
        - `llm_model`: Returns the initialized language model, including its configuration and state, ready for use in various applications. Type should be `LLM_MODEL`.
        - `embed_model_only`: Provides the initialized embedding model separately, including its name, for tasks requiring semantic analysis of text. Type should be `LLM_EMBED_MODEL`.
