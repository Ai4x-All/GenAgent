- `IF_PromptMkr`: The IF_PromptMkr node is designed to transform input prompts into more detailed or stylistically altered prompts, leveraging various AI engines and customization options. It enriches the original prompt with embellishments, styles, or negations based on user-defined parameters, aiming to generate more impactful and contextually rich prompts for creative or analytical applications.
    - Parameters:
        - `input_prompt`: The initial prompt provided by the user, serving as the base for further embellishment or modification. It's crucial for defining the thematic direction of the generated output. Type should be `STRING`.
        - `base_ip`: Specifies the base IP address for the AI engine's API, determining where the request for prompt transformation is sent. Type should be `STRING`.
        - `port`: The port number used in conjunction with the base IP to access the AI engine's API. Type should be `STRING`.
        - `engine`: The choice of AI engine (e.g., ollama, openai, anthropic) to use for processing the input prompt, affecting the style and capabilities of the generated output. Type should be `COMBO[STRING]`.
        - `profile`: A predefined set of parameters or 'profile' that influences the generation process, such as tone or complexity. Type should be `COMBO[STRING]`.
        - `embellish_prompt`: An optional parameter to add additional descriptive elements to the input prompt, enhancing its detail or thematic depth. Type should be `COMBO[STRING]`.
        - `style_prompt`: An optional parameter to apply a specific style or tone to the input prompt, altering its presentation or narrative voice. Type should be `COMBO[STRING]`.
        - `neg_prompt`: An optional parameter to introduce negations or constraints to the input prompt, guiding the generation away from certain themes or concepts. Type should be `COMBO[STRING]`.
        - `temperature`: Controls the creativity or randomness of the generated output, with higher values allowing for more varied responses. Type should be `FLOAT`.
        - `max_tokens`: The maximum number of tokens (words or characters) that the generated output can contain, setting a limit on its length. Type should be `INT`.
        - `seed`: A seed value for the random number generator, ensuring reproducibility of the generated output when set. Type should be `INT`.
        - `random`: A boolean parameter that, when true, uses a random seed for generation, otherwise it uses a fixed temperature setting. Type should be `BOOLEAN`.
        - `keep_alive`: Determines whether the AI model remains loaded after generation, affecting response time and resource usage. Type should be `BOOLEAN`.
    - Inputs:
        - `selected_model`: The specific model selected for generating the output, dependent on the chosen engine and available models. Type should be `[]`.
    - Outputs:
        - `Question`: The original input prompt, returned unchanged as part of the output. Type should be `STRING`.
        - `Response`: The enriched or stylistically altered prompt, generated based on the input prompt and customization options. Type should be `STRING`.
        - `Negative`: A prompt generated with negations or constraints, based on the neg_prompt parameter. Type should be `STRING`.
