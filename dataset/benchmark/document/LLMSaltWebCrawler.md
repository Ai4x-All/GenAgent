- `LLMSaltWebCrawler`: The LLMSaltWebCrawler node is designed for web crawling and content extraction, tailored to efficiently navigate and retrieve information from websites. It leverages advanced parsing techniques to handle different content types (HTML, XML, JSON), assesses page relevance based on specified keywords, and manages link exploration depth and breadth with customizable parameters. This node is adept at extracting structured data from web pages, making it a valuable tool for web scraping, data mining, and content analysis tasks.
    - Inputs:
        - `url` (Optional): The URL to start the crawl from. It serves as the entry point for the web crawling process, determining the initial web page from which the crawler begins its operation. Type should be `STRING`.
        - `urls` (Optional): A list of URLs to be crawled. This allows for multiple entry points for the crawling process, enabling broader coverage of web content. Type should be `LIST`.
        - `max_depth` (Optional): Specifies the maximum depth of the crawl, controlling how deep the crawler can go into website links from the starting point. Type should be `INT`.
        - `max_links` (Optional): The maximum number of links to follow from a single page. This parameter helps in controlling the breadth of the crawl, ensuring a focused and efficient web scraping process. Type should be `INT`.
        - `trim_line_breaks` (Optional): Indicates whether to remove line breaks from the extracted content, which can help in cleaning and standardizing the text data. Type should be `BOOLEAN`.
        - `verify_ssl` (Optional): Determines whether to verify the SSL certificates of the websites being crawled. This can ensure the security of the web crawling process. Type should be `BOOLEAN`.
        - `exclude_domains` (Optional): A list of domains to exclude from the crawl. This helps in avoiding unwanted or irrelevant content by preventing the crawler from accessing specified domains. Type should be `STRING`.
        - `keywords` (Optional): Keywords to filter the content. Pages containing these keywords are considered relevant, allowing for targeted crawling based on content relevance. Type should be `STRING`.
        - `relevant_links` (Optional): Indicates whether to evaluate links for relevance based on the specified keywords. This helps in refining the crawl to include only links that are likely to contain relevant information. Type should be `BOOLEAN`.
        - `relevant_page_content` (Optional): Determines whether to evaluate page content for relevance. This allows for the exclusion of pages that do not contain any of the specified keywords, focusing the crawl on relevant content. Type should be `BOOLEAN`.
        - `max_threads` (Optional): The maximum number of threads to use for parallel crawling. This parameter enhances the efficiency of the crawling process by enabling concurrent fetching of web content. Type should be `INT`.
        - `use_jina` (Optional): A flag indicating whether to use Jina for scraping. This enables the use of Jina's scraping capabilities, potentially improving the efficiency and effectiveness of content retrieval. Type should be `BOOLEAN`.
    - Outputs:
        - `documents`: A collection of documents representing the extracted web page details, including URLs, titles, texts, and links found on the pages. It encapsulates the data mined during the crawl, structured for easy access and analysis. Type should be `DOCUMENT`.
