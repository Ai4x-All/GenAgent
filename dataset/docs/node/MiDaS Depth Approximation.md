- `MiDaS Depth Approximation`: This node utilizes the MiDaS model to approximate depth maps from input images. It supports different MiDaS models and offers options for CPU or GPU execution, depth map inversion, and depth map normalization. The node is designed to enhance image processing tasks by providing detailed depth information, which can be crucial for various applications such as 3D reconstruction, augmented reality, and scene understanding.
    - Parameters:
        - `use_cpu`: A flag to determine whether to use the CPU or GPU for processing. This affects the execution speed and efficiency, especially for large images or batches of images. Type should be `COMBO[STRING]`.
        - `midas_type`: Specifies the type of MiDaS model to be used for depth approximation. Different models may offer varying levels of detail and accuracy. Type should be `COMBO[STRING]`.
        - `invert_depth`: A flag to invert the depth map. This can be useful for certain visualization or processing tasks where the inverse depth representation is preferred. Type should be `COMBO[STRING]`.
    - Inputs:
        - `image`: The input image tensor for which the depth map will be approximated. This tensor is crucial for generating the depth information that can be used for further image processing or analysis tasks. Type should be `IMAGE`.
        - `midas_model`: Optional parameter to specify a pre-loaded MiDaS model and its associated transform. This allows for flexibility in using custom or pre-trained MiDaS models. Type should be `MIDAS_MODEL`.
    - Outputs:
        - `images`: The output depth map tensor, providing a per-pixel depth estimation for the input image. This depth information is valuable for understanding the spatial arrangement of objects in the scene. Type should be `IMAGE`.
