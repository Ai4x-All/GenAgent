- `SAIOpenAIAPIWhisper`: This node provides functionality for transcribing or translating audio content using OpenAI's Whisper API. It supports various configurations for model selection, response formatting, and temperature settings to tailor the transcription or translation process according to specific requirements.
    - Parameters:
        - `file_path`: The path to the audio file to be transcribed or translated. This parameter is crucial for locating and processing the audio content. Type should be `STRING`.
        - `openai_key`: The API key for OpenAI, required for authenticating requests to the Whisper API. Type should be `STRING`.
        - `model`: Specifies the Whisper model to use for transcription or translation, allowing for customization of the process based on model capabilities. Type should be `COMBO[STRING]`.
        - `mode`: Specifies whether the operation is to transcribe or translate the audio content, offering flexibility in processing. Type should be `COMBO[STRING]`.
        - `language`: The language of the audio content, which can influence the transcription or translation accuracy. Type should be `STRING`.
        - `response_format`: Determines the format of the transcription or translation output, supporting text or JSON formats for flexible integration. Type should be `COMBO[STRING]`.
        - `temperature`: Adjusts the creativity or variability of the transcription or translation output, enabling fine-tuning of the results. Type should be `FLOAT`.
        - `timestamp_granularities`: Defines the level of detail for timestamps in the transcription, allowing for segment or word granularity. Type should be `COMBO[STRING]`.
        - `max_frames`: The maximum number of frames to process, enabling control over the scope of transcription or translation. Type should be `INT`.
        - `seek_seconds`: The number of seconds to seek into the audio before starting the transcription or translation, allowing for precise starting points. Type should be `FLOAT`.
        - `prompt`: An optional prompt that can guide the transcription or translation process, providing context or instructions for the model. Type should be `STRING`.
    - Inputs:
    - Outputs:
        - `transcription_result`: The final transcribed or translated text output. Type should be `STRING`.
        - `audio_path`: The path to the processed audio file, useful for subsequent operations or verifications. Type should be `STRING`.
        - `frames_count`: The number of frames processed during the transcription or translation, providing insight into the extent of the operation. Type should be `INT`.
