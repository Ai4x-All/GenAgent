- `SaltCLIPTextEncodeSequence`: The SaltCLIPTextEncodeSequence node is designed for generating a sequence of conditionings based on a schedule of text prompts for audio visualization. It utilizes CLIP models to encode text prompts into conditionings, adjusting for frame counts and applying token normalization and weight interpretation strategies to tailor the output for specific visualization needs.
    - Parameters:
        - `token_normalization`: Specifies the method for normalizing the tokens generated from the text prompts, affecting how the text is processed and encoded into conditionings. Type should be `COMBO[STRING]`.
        - `weight_interpretation`: Determines how the weights are interpreted during the encoding process, influencing the final conditioning output for visualization. Type should be `COMBO[STRING]`.
        - `frame_count`: The total number of frames for which conditionings need to be generated, guiding the sequence generation process. Type should be `INT`.
        - `text`: A schedule of text prompts provided in a structured format, dictating the content and timing for each frame in the sequence. Type should be `STRING`.
    - Inputs:
        - `clip`: The CLIP model used for encoding the text prompts into a conditioning format. It plays a crucial role in interpreting the text and converting it into a form that can be utilized for generating visualizations. Type should be `CLIP`.
    - Outputs:
        - `conditioning_sequence`: A sequence of conditionings generated based on the provided text prompts and frame count, tailored for audio visualization purposes. Type should be `CONDITIONING`.
        - `frame_count`: The total number of frames for which conditionings have been generated, reflecting the input frame count. Type should be `INT`.
