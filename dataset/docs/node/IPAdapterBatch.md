- `IPAdapterBatch`: The IPAdapterBatch node is designed for batch processing of images with advanced IPAdapter configurations, enabling the application of image processing techniques and model adjustments across multiple images simultaneously. It extends the capabilities of IPAdapterAdvanced by allowing for batch operations, thus optimizing workflow efficiency and processing speed.
    - Parameters:
        - `weight`: A float value or a range of values specifying the weight of the processing effect, influencing the intensity of the applied adjustments. Type should be `FLOAT`.
        - `weight_type`: Determines the type of weighting applied to the processing, affecting how the adjustments are balanced and applied. Type should be `COMBO[STRING]`.
        - `start_at`: A float specifying the starting point of processing within a given range, allowing for fine-tuned control over the application of adjustments. Type should be `FLOAT`.
        - `end_at`: A float defining the end point of processing within a given range, enabling precise control over the extent of adjustments applied. Type should be `FLOAT`.
        - `embeds_scaling`: Specifies the method of embedding scaling, affecting the adaptation of embeddings to the image processing task. Type should be `COMBO[STRING]`.
    - Inputs:
        - `model`: Specifies the model to be used for image processing, central to the node's operation and determining the processing capabilities. Type should be `MODEL`.
        - `ipadapter`: Defines the IPAdapter configuration to be applied, crucial for determining the specific image processing techniques and adjustments. Type should be `IPADAPTER`.
        - `image`: The image(s) to be processed, can be a single image or a batch of images, serving as the primary input for processing. Type should be `IMAGE`.
        - `image_negative`: An optional image input that serves as a negative reference, guiding the processing in a direction opposite to the provided image. Type should be `IMAGE`.
        - `attn_mask`: An optional mask that directs attention to specific areas of the image during processing, enhancing focus on relevant features. Type should be `MASK`.
        - `clip_vision`: An optional CLIP vision model input that can be used to guide the image processing with visual concepts derived from text descriptions. Type should be `CLIP_VISION`.
    - Outputs:
        - `model`: The processed model after applying the IPAdapter configurations and adjustments to the input images. Type should be `MODEL`.
