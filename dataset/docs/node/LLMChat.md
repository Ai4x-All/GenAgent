- `LLMChat`: The LLMChat node facilitates interactive conversations with a language model by processing user inputs and generating responses. It leverages document embedding, message templating, and query engines to simulate a chat environment, allowing for dynamic and context-aware dialogues.
    - Parameters:
        - `prompt`: The user's input or question to the language model, serving as the basis for generating a response. Type should be `STRING`.
    - Inputs:
        - `llm_model`: A dictionary specifying the language model and its embedding model used for generating responses and processing documents. Type should be `LLM_MODEL`.
        - `llm_context`: Optional context information for the language model, used to tailor responses more closely to the given scenario. Type should be `LLM_CONTEXT`.
        - `llm_message`: A list of chat messages that provide context or history for the conversation, enhancing the relevance of the model's response. Type should be `LIST`.
        - `llm_documents`: Optional documents provided to enrich the conversation context or serve as reference material for the language model. Type should be `DOCUMENT`.
    - Outputs:
        - `response`: The generated response from the language model to the user's prompt. Type should be `STRING`.
